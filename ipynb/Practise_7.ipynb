{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8b5e9de",
   "metadata": {},
   "source": [
    "# –†–∞–±–æ—á–∞—è —Ç–µ—Ç—Ä–∞–¥—å ‚Ññ7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e9a93",
   "metadata": {},
   "source": [
    "## –î—É–¥–∏–Ω –ê–ª–µ–∫—Å–µ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929da30",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d37a5",
   "metadata": {},
   "source": [
    "–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å –∫–ª–∞—Å—Å–æ–º OurNeuralNetwork. \n",
    "\n",
    "–î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "‚àí —Ç—Ä–∏ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2, ùë•3);\n",
    "‚àí —Ç—Ä–∏ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (h1, h2, h3);\n",
    "‚àí –≤—ã—Ö–æ–¥ (ùëú1).\n",
    "\n",
    "–ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "‚àí ùë§ = [0.5, 0.5, 0.5]\n",
    "‚àíùëè=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54c6a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    \n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8374b7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9222286937644897\n"
     ]
    }
   ],
   "source": [
    "class OurNeuralNetwork1:\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 1\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "        \n",
    "network = OurNeuralNetwork1()\n",
    "x = np.array([1, 2, 3])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feed598",
   "metadata": {},
   "source": [
    "–î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "‚àí –¥–≤–∞ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2);\n",
    "‚àí –¥–≤–∞ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (h1, h2);\n",
    "‚àí –¥–≤–∞ –≤—ã—Ö–æ–¥–∞ (ùëú1, ùëú2).\n",
    "\n",
    "–ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏: ‚àí ùë§ = [1,0];\n",
    "‚àí ùëè = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c66051dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8677026536525567, 0.8677026536525567)\n"
     ]
    }
   ],
   "source": [
    "class OurNeuralNetwork2:\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0])\n",
    "        bias = 1\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1, out_o2\n",
    "        \n",
    "network = OurNeuralNetwork2()\n",
    "x = np.array([1, 2])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00bea33",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27954de",
   "metadata": {},
   "source": [
    "–†–µ–∞–ª–∏–∑—É–π—Ç–µ –∫–ª–∞—Å—Å—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥—Ä—É–≥–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1050b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9613959740515259\n"
     ]
    }
   ],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    \n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return tanh(total)\n",
    "    \n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0])\n",
    "        bias = 1\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1\n",
    "        \n",
    "network = NeuralNetwork()\n",
    "x = np.array([1, 2])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb99399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    \n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return ReLU(total)\n",
    "    \n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0])\n",
    "        bias = 1\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1\n",
    "        \n",
    "network = NeuralNetwork()\n",
    "x = np.array([1, 2])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e85a6b",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10d654",
   "metadata": {},
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–ª–∞—Å—Å—ã MLPClassified –∏ MLPRegressor –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –∞—Ç—Ä–∏–±—É—Ç—ã, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.\n",
    "–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–∂–µ—Ç–µ –≤–∑—è—Ç—å –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ò—Ä–∏—Å–æ–≤: https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
    "–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã –æ—Ç –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã: https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d812b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from munch) (1.16.0)\n",
      "Installing collected packages: munch\n",
      "Successfully installed munch-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install munch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3af831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (30, 4) (120,) (30,)\n",
      "['Versicolor' 'Setosa' 'Setosa' 'Versicolor' 'Setosa' 'Setosa' 'Setosa'\n",
      " 'Setosa' 'Setosa' 'Virginica' 'Virginica' 'Setosa' 'Setosa' 'Virginica'\n",
      " 'Virginica']\n",
      "82     Versicolor\n",
      "37         Setosa\n",
      "38         Setosa\n",
      "76     Versicolor\n",
      "28         Setosa\n",
      "3          Setosa\n",
      "17         Setosa\n",
      "25         Setosa\n",
      "42         Setosa\n",
      "108     Virginica\n",
      "120     Virginica\n",
      "43         Setosa\n",
      "23         Setosa\n",
      "109     Virginica\n",
      "124     Virginica\n",
      "Name: variety, dtype: object\n",
      "Test Accurancy: 0.967\n",
      "Training Accurancy: 0.975\n",
      "Loss:  0.08026595018018393\n",
      "Number of coefs:  2\n",
      "Number of intercepts:  2\n",
      "Number of iterations for which estimator ran:  638\n",
      "Name of output layer activation function:  softmax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "url = r'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.iloc[:,:-1],    # –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π - –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    data.iloc[:,-1], # –ø–æ—Å–ª–µ–¥–Ω—é—é –≤ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–∫–ª–∞—Å—Å)\n",
    "    test_size = 0.20 # —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ 20%\n",
    ")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "mlp_classifier = MLPClassifier(random_state=123, max_iter=1000)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "Y_preds = mlp_classifier.predict(X_test)\n",
    "\n",
    "print(Y_preds[:15])\n",
    "print(y_test[:15])\n",
    "\n",
    "## Score - –æ—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "print('Test Accurancy: %.3f'%mlp_classifier.score(X_test, y_test))\n",
    "print('Training Accurancy: %.3f'%mlp_classifier.score(X_train, y_train))\n",
    "print(\"Loss: \", mlp_classifier.loss_)\n",
    "print(\"Number of coefs: \", len(mlp_classifier.coefs_))\n",
    "print(\"Number of intercepts: \", len(mlp_classifier.intercepts_))\n",
    "print(\"Number of iterations for which estimator ran: \", mlp_classifier.n_iter_)\n",
    "print(\"Name of output layer activation function: \", mlp_classifier.out_activation_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8421e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1) (6, 1) (24,) (6,)\n",
      "[ 55265.2045971  126554.5591937   52335.80522199 116782.59147446\n",
      "  55265.2045971  117759.05793283]\n",
      "[ 54445. 121872.  56642. 116969.  64445. 112635.]\n",
      "Test R^2: 0.971\n",
      "Training R^2: 0.948\n",
      "Loss:  16873681.689960096\n",
      "Number of coefs:  2\n",
      "Number of intercepts:  2\n",
      "Number of iterations for which estimator ran:  30344\n",
      "Name of output layer activation function:  identity\n"
     ]
    }
   ],
   "source": [
    "url = r'https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv'\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.iloc[:,:-1].values,    # –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π - –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    data.iloc[:,-1].values, # –ø–æ—Å–ª–µ–¥–Ω—é—é –≤ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–∫–ª–∞—Å—Å)\n",
    "    test_size = 0.20, # —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ 20%\n",
    "    random_state=123\n",
    ")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "mlp_regressor = MLPRegressor(random_state=123, max_iter = 32000)\n",
    "mlp_regressor.fit(X_train, y_train)\n",
    "Y_preds = mlp_regressor.predict(X_test)\n",
    "\n",
    "print(Y_preds[:10])\n",
    "print(y_test[:10])\n",
    "## –º–µ—Ç–æ–¥ Score –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "print('Test R^2: %.3f'%mlp_regressor.score(X_test, y_test))\n",
    "print('Training R^2: %.3f'%mlp_regressor.score(X_train, y_train))\n",
    "print(\"Loss: \", mlp_regressor.loss_)\n",
    "print(\"Number of coefs: \", len(mlp_regressor.coefs_))\n",
    "print(\"Number of intercepts: \", len(mlp_regressor.intercepts_))\n",
    "print(\"Number of iterations for which estimator ran: \", mlp_regressor.n_iter_)\n",
    "print(\"Name of output layer activation function: \", mlp_regressor.out_activation_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109c71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
